{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from sklearn.utils import shuffle\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "# import tqdm\n",
    "from PIL import Image\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.core import Flatten, Dropout\n",
    "from keras.layers import Input, merge\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import matplotlib.pyplot as plt\n",
    "# from misc_layers import MinibatchDiscrimination, SubPixelUpscaling, CustomLRELU, bilinear2x\n",
    "# from keras_contrib.layers import SubPixelUpscaling\n",
    "import keras.backend as K\n",
    "from keras.initializers import RandomNormal\n",
    "# K.set_image_dim_ordering('tf')\n",
    "\n",
    "import glob\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "# from sklearn.utils import shuffle\n",
    "import scipy\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "# from scipy.interpolate import spline\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from collections import deque\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_img(img):\n",
    "    img = (img / 127.5) - 1\n",
    "    #image normalisation to keep values between -1 and 1 for stability\n",
    "    return img\n",
    "\n",
    "def denorm_img(img):\n",
    "    #for output\n",
    "    img = (img + 1) * 127.5\n",
    "    return img.astype(np.uint8) \n",
    "\n",
    "\n",
    "def sample_from_dataset(batch_size, image_shape, data_dir=None, data = None):\n",
    "    sample_dim = (batch_size,) + image_shape\n",
    "    sample = np.empty(sample_dim, dtype=np.float32)\n",
    "    \n",
    "    sample_imgs_paths = [join(data_dir, f) for f in listdir(data_dir) if 'png' in f]\n",
    "    sample_imgs_paths = np.random.choice(sample_imgs_paths,batch_size)\n",
    "    for index,img_filename in enumerate(sample_imgs_paths):\n",
    "        image = Image.open(img_filename)\n",
    "        image = image.resize(image_shape[:-1])\n",
    "        image = image.convert('RGB')\n",
    "        image = np.asarray(image)\n",
    "        image = norm_img(image)\n",
    "        sample[index,...] = image\n",
    "    return sample\n",
    "\n",
    "def gen_noise(batch_size, noise_shape):\n",
    "    #input noise for the generator should follow a probability distribution, like in this case, the normal distributon.\n",
    "    return np.random.normal(0, 1, size=(batch_size,)+noise_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_normal(noise_shape):\n",
    "    noise_shape = noise_shape\n",
    "    \n",
    "    kernel_init = 'glorot_uniform'\n",
    "    \n",
    "    gen_input = Input(shape = noise_shape)\n",
    "    generator = Conv2DTranspose(filters = 512, kernel_size = (4,4), strides = (1,1), padding = \"valid\", data_format = \"channels_last\", kernel_initializer = kernel_init)(gen_input)\n",
    "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "        \n",
    "    generator = Conv2DTranspose(filters = 256, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
    "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "    \n",
    "    generator = Conv2DTranspose(filters = 128, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
    "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "    \n",
    "    generator = Conv2DTranspose(filters = 64, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
    "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "    \n",
    "    generator = Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
    "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "    \n",
    "    generator = Conv2DTranspose(filters = 3, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
    "    generator = Activation('tanh')(generator)\n",
    "        \n",
    "    gen_opt = Adam(lr=0.00015, beta_1=0.5)\n",
    "    generator_model = Model(input = gen_input, output = generator)\n",
    "    generator_model.compile(loss='binary_crossentropy', optimizer=gen_opt, metrics=['accuracy'])\n",
    "#     generator_model.summary()\n",
    "\n",
    "    return generator_model\n",
    "\n",
    "\n",
    "\n",
    "def get_disc_normal(image_shape=(64,64,3)):\n",
    "    image_shape = image_shape\n",
    "    \n",
    "    dropout_prob = 0.2\n",
    "    kernel_init = 'glorot_uniform'\n",
    "    dis_input = Input(shape = image_shape)\n",
    "    discriminator = Conv2D(filters = 64, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(dis_input)\n",
    "    discriminator = LeakyReLU(0.2)(discriminator)\n",
    "    discriminator = Conv2D(filters = 128, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(discriminator)\n",
    "    discriminator = BatchNormalization(momentum = 0.5)(discriminator)\n",
    "    discriminator = LeakyReLU(0.2)(discriminator)\n",
    "   \n",
    "    discriminator = Conv2D(filters = 256, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(discriminator)\n",
    "    discriminator = BatchNormalization(momentum = 0.5)(discriminator)\n",
    "    discriminator = LeakyReLU(0.2)(discriminator)\n",
    "    \n",
    "    discriminator = Conv2D(filters = 512, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(discriminator)\n",
    "    discriminator = BatchNormalization(momentum = 0.5)(discriminator)\n",
    "    discriminator = LeakyReLU(0.2)(discriminator)\n",
    "    \n",
    "    discriminator = Flatten()(discriminator)\n",
    "    \n",
    "    discriminator = Dense(1)(discriminator)\n",
    "    discriminator = Activation('sigmoid')(discriminator)\n",
    "    #also try the SGD optimiser, might work better for a few learning rates.\n",
    "    dis_opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    discriminator_model = Model(input = dis_input, output = discriminator)\n",
    "    discriminator_model.compile(loss='binary_crossentropy', optimizer=dis_opt, metrics=['accuracy'])\n",
    "#     discriminator_model.summary()\n",
    "    return discriminator_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_shape = (1,1,100)\n",
    "batch_size = 64\n",
    "img_save_dir = \"./output_source_word/\"\n",
    "image_shape = (64,64,3)\n",
    "data_dir =  \"./input_source_word/\"\n",
    "\n",
    "save_model_dir = './model_source_word/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = get_disc_normal(image_shape)\n",
    "generator = get_gen_normal(noise_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "\n",
    "opt = Adam(lr=0.00015, beta_1=0.5) \n",
    "gen_inp = Input(shape=noise_shape)\n",
    "GAN_inp = generator(gen_inp)\n",
    "GAN_opt = discriminator(GAN_inp)\n",
    "gan = Model(input = gen_inp, output = GAN_opt)\n",
    "gan.compile(loss = 'binary_crossentropy', optimizer = opt, metrics=['accuracy'])\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_images(img_batch):\n",
    "    rand_index = np.random.randint(img_batch.shape[0])\n",
    "    rand_index = 0\n",
    "    image = img_batch[rand_index, :,:,:]\n",
    "    return denorm_img(image)\n",
    "\n",
    "def save_img_one_batch(plt, img_batch, img_save_dir, step):\n",
    "    image = get_sample_images(img_batch)\n",
    "    plt.imshow(image)\n",
    "    plt.savefig(img_save_dir, bbox_inches='tight', pad_inches=0)\n",
    "def plot_history_loss():\n",
    "    plt.figure(figsize=(20,5))\n",
    "    length = 8000\n",
    "    plt.ylim(0, 1.0)\n",
    "    x = range(len(real_loss_array[:length]))\n",
    "    plt.plot(x, real_loss_array[:length], '-r', x, fake_loss_array[:length], '-g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_step = 0\n",
    "num_steps = init_step + 10500\n",
    "# batch_size = 5\n",
    "# print(init_step, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "avg_disc_real_loss = deque([0], maxlen=250)\n",
    "avg_GAN_loss = deque([0], maxlen=250)\n",
    "\n",
    "real_loss_array, global_loss_array = [], []\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.axis('off')\n",
    "batch_size = 5\n",
    "for step in range(init_step, num_steps): \n",
    "    if ((step + 1) % 250) == 0:\n",
    "        print(\"Begin step: \", step)\n",
    "    \n",
    "    # Learning D\n",
    "    real_data_X = sample_from_dataset(batch_size, image_shape, data_dir = data_dir)\n",
    "    noise = gen_noise(batch_size,noise_shape)\n",
    "    fake_data_X = generator.predict(noise)\n",
    "    \n",
    "    real_data_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0\n",
    "    fake_data_Y = np.random.random_sample(batch_size)*0.01\n",
    "    \n",
    "#     data_X = np.concatenate([real_data_X, fake_data_X])\n",
    "#     data_Y = np.concatenate((real_data_Y, fake_data_Y))\n",
    "        \n",
    "    discriminator.trainable = True\n",
    "    generator.trainable = False\n",
    "    dis_metrics_real = discriminator.train_on_batch(real_data_X, real_data_Y) \n",
    "    dis_metrics_fake = discriminator.train_on_batch(fake_data_X, fake_data_Y) \n",
    "    \n",
    "    \n",
    "    # Learning G\n",
    "    generator.trainable = True\n",
    "    discriminator.trainable = False\n",
    "    GAN_X = gen_noise(batch_size,noise_shape)\n",
    "    GAN_Y = real_data_Y\n",
    "    gan_metrics = gan.train_on_batch(GAN_X,GAN_Y)\n",
    "    \n",
    "    \n",
    "    # tracking \n",
    "    real_loss_array.append(dis_metrics_real[0])\n",
    "    global_loss_array.append(gan_metrics[0])\n",
    "    if (step+1) % 50 == 0:\n",
    "        step_num = str(step).zfill(4)\n",
    "        save_img_one_batch(plt, fake_data_X, img_save_dir+step_num+\"_image.png\", step)\n",
    "        \n",
    "        \n",
    "    real_loss_array.append(dis_metrics_real[0])\n",
    "    avg_GAN_loss.append(gan_metrics[0])\n",
    "    if (((step+1) % 1000) == 0) or (step == num_steps - 1):\n",
    "        print(\"-----------------------------------------------------------------\")\n",
    "        print(\"Average Disc_real loss: %f\" % (np.mean(avg_disc_real_loss)))    \n",
    "        print(\"Average GAN loss: %f\" % (np.mean(avg_GAN_loss)))\n",
    "        print(\"-----------------------------------------------------------------\")\n",
    "        discriminator.trainable = True\n",
    "        generator.trainable = True\n",
    "        generator.save(save_model_dir+str(step)+\"_GENERATOR_weights_and_arch.hdf5\")\n",
    "        discriminator.save(save_model_dir+str(step)+\"_DISCRIMINATOR_weights_and_arch.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
